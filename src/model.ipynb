{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import utils\n",
    "import os\n",
    "import numpy as np\n",
    "import xgboost\n",
    "from joblib import dump, load\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "data_dir = './data'\n",
    "preprocessed_data_dir = './preprocessed_data/'\n",
    "label_dir = os.path.join(data_dir, \"prescreened_train_labels.csv.bz2\")\n",
    "predict_dir = os.path.join(data_dir, \"partial_submission_format.csv\")\n",
    "predictions = pd.read_csv(predict_dir, parse_dates=[\"timestamp\"])\n",
    "submission = predictions.copy().reset_index(drop=True)\n",
    "submission[\"active\"] = np.nan"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "unique_config_maps = {}\n",
    "airport_codes = []\n",
    "grouped = submission.groupby([\"airport\"], sort=False)\n",
    "for key, group in grouped:\n",
    "    unique_config_maps[key] = group.config.unique()\n",
    "    airport_codes.append(key)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "['katl',\n 'kclt',\n 'kden',\n 'kdfw',\n 'kjfk',\n 'kmem',\n 'kmia',\n 'kord',\n 'kphx',\n 'ksea',\n 'open_train_labels.csv',\n 'open_train_labels.csv.bz2',\n 'partial_submission_format.csv',\n 'prescreened_train_labels.csv.bz2']"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code to prepare the datasets.\n",
    "# feature_directory = Path(\"../../data\")\n",
    "# airport_directories = sorted(path for path in feature_directory.glob(\"k*\"))\n",
    "#\n",
    "# airport_train_map = {}\n",
    "# airport_codes = []\n",
    "# for airport_directory in sorted(airport_directories):\n",
    "#     airport_code, airport_config_df = utils.read_airport_configs(airport_directory)\n",
    "#     #airport_config_df_map[airport_code] = airport_config_df\n",
    "#     airport_config_df = utils.clean_airport_configs(airport_config_df, unique_config_maps[airport_code], airport_code)\n",
    "#\n",
    "#     print(len(airport_config_df.airport_config.unique()))\n",
    "#     airport_codes.append(airport_code)\n",
    "#\n",
    "#     airport_code, airport_weather_df = utils.read_airport_weather_data(airport_directory)\n",
    "#     #airport_weather_df_map[airport_code] = airport_weather_df\n",
    "#\n",
    "#     airport_label_df = utils.split_labels_into_airports(label_dir, airport_code)\n",
    "#     airport_train_map[airport_code] = utils.create_train_dataset(airport_label_df, airport_weather_df, airport_config_df)\n",
    "#     print(airport_code)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "def split_data(dataframe, unique_labels, test_size=0.2, random_state=1234):\n",
    "    unique_config_rows = dataframe.copy().drop_duplicates(subset=['true_labels'])\n",
    "    dataframe = dataframe[~dataframe.isin(unique_config_rows)].dropna(how='all')\n",
    "\n",
    "    missing_configs = set(unique_labels) - set(unique_config_rows['true_labels'])\n",
    "    print(missing_configs)\n",
    "\n",
    "    # Fill any missing configs randomly. Not the most elegant, but works.\n",
    "    fill_rows = dataframe.dropna(axis=0).sample(n=len(missing_configs))\n",
    "    for idx, config in enumerate(missing_configs):\n",
    "        cur_row = fill_rows.iloc[[idx]]\n",
    "        cur_row.true_labels = config\n",
    "        cur_row.previous_config = config\n",
    "        unique_config_rows = pd.concat([unique_config_rows, cur_row])\n",
    "\n",
    "    train_set, test_set = train_test_split(dataframe, test_size=test_size, random_state=random_state)\n",
    "    train_set = pd.concat([train_set, unique_config_rows])\n",
    "    return train_set, test_set\n",
    "\n",
    "\n",
    "def pre_pipeline_data(dataframe):\n",
    "    dataframe = dataframe.drop(['time_pred_made', 'target_pred_timestamp', 'time_forecast_made', 'forecast_timestamp'], axis=1)\n",
    "    dataframe = dataframe.dropna(axis=0)\n",
    "\n",
    "    # After removing NAs, get the labels.\n",
    "    y_train = dataframe['true_labels']\n",
    "    dataframe = dataframe.drop(['true_labels'], axis=1)\n",
    "    return dataframe, y_train\n",
    "\n",
    "def make_uniform(num_vals):\n",
    "    array = np.ones((num_vals,))\n",
    "    array = softmax(array)\n",
    "    return array\n",
    "\n",
    "\n",
    "def divide(arr):\n",
    "    return arr / sum(arr)\n",
    "\n",
    "\n",
    "def merge_preds(pred_matrix):\n",
    "    size = pred_matrix.shape[1]\n",
    "    arr = .05*make_uniform(size) + .95*pred_matrix\n",
    "    arr = np.apply_along_axis(divide, 1, arr)\n",
    "    return arr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Files\\Applications\\Anaconda\\envs\\ConfigPred\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3369: DtypeWarning: Columns (16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "airport_train_map = {}\n",
    "for code in airport_codes:\n",
    "    airport_train_map[code] = pd.read_csv(preprocessed_data_dir + code + \"train.csv\",\n",
    "                                          parse_dates=['time_pred_made', 'target_pred_timestamp', 'time_forecast_made', 'forecast_timestamp'],\n",
    "                                          index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'katl:D_9L_A_9R'}\n",
      "katl\n",
      "0.3160810833221516\n",
      "0.9033171521035599\n",
      "set()\n",
      "kclt\n",
      "0.35111346185780706\n",
      "0.8860855496005663\n",
      "set()\n",
      "kden\n",
      "1.1099512518157766\n",
      "0.6701557443365695\n",
      "set()\n",
      "kdfw\n",
      "0.48675390537808866\n",
      "0.8492769744160178\n",
      "set()\n",
      "kjfk\n",
      "0.2099466961531511\n",
      "0.9332490518331227\n",
      "set()\n",
      "kmem\n",
      "0.7135362830470742\n",
      "0.7660768452982811\n",
      "set()\n",
      "kmia\n",
      "0.4135162366307961\n",
      "0.8736916620316529\n",
      "set()\n",
      "kord\n",
      "0.885584990241789\n",
      "0.7204186893203883\n",
      "set()\n",
      "kphx\n",
      "0.4131870075396187\n",
      "0.8736852750809061\n",
      "set()\n",
      "ksea\n",
      "0.2271242917852956\n",
      "0.9265888063097224\n"
     ]
    }
   ],
   "source": [
    "model_map = {}\n",
    "data_pipeline_map = {}\n",
    "label_enc_map = {}\n",
    "train_data_map = {}\n",
    "test_data_map = {}\n",
    "\n",
    "for airport in airport_codes:\n",
    "    current_data = airport_train_map[airport]\n",
    "    current_label_configs = unique_config_maps[airport]\n",
    "    train_set, test_set = split_data(current_data, current_label_configs, test_size=0.2, random_state=1234)\n",
    "\n",
    "    x_train, y_train = pre_pipeline_data(train_set)\n",
    "    x_test, y_test = pre_pipeline_data(test_set)\n",
    "\n",
    "    data_pipeline, label_enc = utils.get_pipeline(current_label_configs)\n",
    "\n",
    "    x_train_piped = data_pipeline.fit_transform(x_train)\n",
    "    y_train_piped = label_enc.transform(y_train)\n",
    "\n",
    "    x_test_piped = data_pipeline.transform(x_test)\n",
    "    y_test_piped = label_enc.transform(y_test)\n",
    "\n",
    "    xgb = xgboost.XGBClassifier(objective='multi:softprob', random_state=52, n_estimators=725, eval_metric='mlogloss', n_jobs=-1, use_label_encoder=False)\n",
    "    rf = RandomForestClassifier(n_estimators=150, n_jobs=-1, random_state=123)\n",
    "\n",
    "    voting_classifier = VotingClassifier(estimators=[('xgboost', xgb), ('rf', rf)],\n",
    "                                         voting='soft', n_jobs=-1, verbose=True, weights=[.75, .25])\n",
    "    voting_classifier = voting_classifier.fit(x_train_piped, y_train_piped)\n",
    "\n",
    "    print(airport)\n",
    "    preds = voting_classifier.predict_proba(x_test_piped)\n",
    "    cat_preds = voting_classifier.predict(x_test_piped)\n",
    "    print(log_loss(to_categorical(y_test_piped), preds, eps=1e-16))\n",
    "    print(accuracy_score(y_test_piped, cat_preds))\n",
    "\n",
    "    data_pipeline_map[airport] = data_pipeline\n",
    "    label_enc_map[airport] = label_enc\n",
    "    train_data_map[airport] = (x_train, y_train)\n",
    "    test_data_map[airport] = (x_test, y_test)\n",
    "    model_map[airport] = voting_classifier\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for airport in airport_codes:\n",
    "    with open(f'model_assets/{airport}_model.joblib', 'wb') as file:\n",
    "        dump(model_map[airport], file)\n",
    "\n",
    "with open(\"model_assets/saved_data_pipeline_map.pkl\", 'wb') as file:\n",
    "    pickle.dump(data_pipeline_map, file, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(\"model_assets/saved_label_enc_map.pkl\", 'wb') as file:\n",
    "    pickle.dump(label_enc_map, file, pickle.HIGHEST_PROTOCOL)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-c6f0381a",
   "language": "python",
   "display_name": "PyCharm (benchmark_src)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}